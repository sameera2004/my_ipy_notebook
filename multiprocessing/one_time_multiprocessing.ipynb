{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skbeam.core.correlation as corr\n",
    "import skbeam.core.roi as roi\n",
    "import skbeam.core.utils as utils\n",
    "\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "import time as ttime\n",
    "\n",
    "p = Pool(processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "results = namedtuple(\n",
    "    'correlation_results',\n",
    "    ['g2', 'lag_steps', 'internal_state']\n",
    ")\n",
    "\n",
    "_internal_state = namedtuple(\n",
    "    'correlation_state',\n",
    "    ['buf',\n",
    "     'G',\n",
    "     'past_intensity',\n",
    "     'future_intensity',\n",
    "     'img_per_level',\n",
    "     'label_array',\n",
    "     'track_level',\n",
    "     'cur',\n",
    "     'pixel_list',\n",
    "     'num_pixels',\n",
    "     'lag_steps',\n",
    "     'norm',\n",
    "     'lev_len']\n",
    ")\n",
    "\n",
    "\n",
    "def _init_state_one_time(num_levels, num_bufs, labels):\n",
    "    \"\"\"Initialize a stateful namedtuple for the generator-based multi-tau\n",
    "     for one time correlation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_levels : int\n",
    "    num_bufs : int\n",
    "    labels : array\n",
    "        Two dimensional labeled array that contains ROI information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    internal_state : namedtuple\n",
    "        The namedtuple that contains all the state information that\n",
    "        `lazy_one_time` requires so that it can be used to pick up\n",
    "         processing after it was interrupted\n",
    "    \"\"\"\n",
    "    (label_array, pixel_list, num_rois, num_pixels, lag_steps, buf,\n",
    "     img_per_level, track_level, cur, norm,\n",
    "     lev_len) = _validate_and_transform_inputs(num_bufs, num_levels, labels)\n",
    "\n",
    "    # G holds the un normalized auto- correlation result. We\n",
    "    # accumulate computations into G as the algorithm proceeds.\n",
    "    G = np.zeros(((num_levels + 1) * num_bufs / 2, num_rois),\n",
    "                 dtype=np.float64)\n",
    "    # matrix for normalizing G into g2\n",
    "    past_intensity = np.zeros_like(G)\n",
    "    # matrix for normalizing G into g2\n",
    "    future_intensity = np.zeros_like(G)\n",
    "\n",
    "    return _internal_state(\n",
    "        buf,\n",
    "        G,\n",
    "        past_intensity,\n",
    "        future_intensity,\n",
    "        img_per_level,\n",
    "        label_array,\n",
    "        track_level,\n",
    "        cur,\n",
    "        pixel_list,\n",
    "        num_pixels,\n",
    "        lag_steps,\n",
    "        norm,\n",
    "        lev_len,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def lazy_one_time(image_iterable, num_levels, num_bufs, labels,\n",
    "                  internal_state=None):\n",
    "    \"\"\"Generator implementation of 1-time multi-tau correlation\n",
    "\n",
    "    If you do not want multi-tau correlation, set num_levels to 1 and\n",
    "    num_bufs to the number of images you wish to correlate\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_iterable : iterable of 2D arrays\n",
    "    num_levels : int\n",
    "        how many generations of downsampling to perform, i.e., the depth of\n",
    "        the binomial tree of averaged frames\n",
    "    num_bufs : int, must be even\n",
    "        maximum lag step to compute in each generation of downsampling\n",
    "    labels : array\n",
    "        Labeled array of the same shape as the image stack.\n",
    "        Each ROI is represented by sequential integers starting at one.  For\n",
    "        example, if you have four ROIs, they must be labeled 1, 2, 3,\n",
    "        4. Background is labeled as 0\n",
    "    internal_state : namedtuple, optional\n",
    "        internal_state is a bucket for all of the internal state of the\n",
    "        generator. It is part of the `results` object that is yielded from\n",
    "        this generator\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    namedtuple\n",
    "        A `results` object is yielded after every image has been processed.\n",
    "        This `reults` object contains, in this order:\n",
    "        - `g2`: the normalized correlation\n",
    "          shape is (len(lag_steps), num_rois)\n",
    "        - `lag_steps`: the times at which the correlation was computed\n",
    "        - `_internal_state`: all of the internal state. Can be passed back in\n",
    "          to `lazy_one_time` as the `internal_state` parameter\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The normalized intensity-intensity time-autocorrelation function\n",
    "    is defined as\n",
    "\n",
    "    .. math::\n",
    "        g_2(q, t') = \\\\frac{<I(q, t)I(q, t + t')> }{<I(q, t)>^2}\n",
    "\n",
    "        t' > 0\n",
    "\n",
    "    Here, ``I(q, t)`` refers to the scattering strength at the momentum\n",
    "    transfer vector ``q`` in reciprocal space at time ``t``, and the brackets\n",
    "    ``<...>`` refer to averages over time ``t``. The quantity ``t'`` denotes\n",
    "    the delay time\n",
    "\n",
    "    This implementation is based on published work. [1]_\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] D. Lumma, L. B. Lurio, S. G. J. Mochrie and M. Sutton,\n",
    "        \"Area detector based photon correlation in the regime of\n",
    "        short data batches: Data reduction for dynamic x-ray\n",
    "        scattering,\" Rev. Sci. Instrum., vol 70, p 3274-3289, 2000.\n",
    "    \"\"\"\n",
    "\n",
    "    if internal_state is None:\n",
    "        internal_state = _init_state_one_time(num_levels, num_bufs, labels)\n",
    "    # create a shorthand reference to the results and state named tuple\n",
    "    s = internal_state\n",
    "\n",
    "    # iterate over the images to compute multi-tau correlation\n",
    "    for image in image_iterable:\n",
    "        # Compute the correlations for all higher levels.\n",
    "        level = 0\n",
    "\n",
    "        # increment buffer\n",
    "        s.cur[0] = (1 + s.cur[0]) % num_bufs\n",
    "\n",
    "        # Put the ROI pixels into the ring buffer.\n",
    "        s.buf[0, s.cur[0] - 1] = np.ravel(image)[s.pixel_list]\n",
    "        buf_no = s.cur[0] - 1\n",
    "        # Compute the correlations between the first level\n",
    "        # (undownsampled) frames. This modifies G,\n",
    "        # past_intensity, future_intensity,\n",
    "        # and img_per_level in place!\n",
    "        _one_time_process(s.buf, s.G, s.past_intensity, s.future_intensity,\n",
    "                          s.label_array, num_bufs, s.num_pixels,\n",
    "                          s.img_per_level, level, buf_no, s.norm, s.lev_len)\n",
    "\n",
    "        # check whether the number of levels is one, otherwise\n",
    "        # continue processing the next level\n",
    "        processing = num_levels > 1\n",
    "\n",
    "        level = 1\n",
    "        while processing:\n",
    "            if not s.track_level[level]:\n",
    "                s.track_level[level] = True\n",
    "                processing = False\n",
    "            else:\n",
    "                prev = (1 + (s.cur[level - 1] - 2) % num_bufs)\n",
    "                s.cur[level] = (\n",
    "                    1 + s.cur[level] % num_bufs)\n",
    "\n",
    "                s.buf[level, s.cur[level] - 1] = ((\n",
    "                        s.buf[level - 1, prev - 1] +\n",
    "                        s.buf[level - 1, s.cur[level - 1] - 1]) / 2)\n",
    "\n",
    "                # make the track_level zero once that level is processed\n",
    "                s.track_level[level] = False\n",
    "\n",
    "                # call processing_func for each multi-tau level greater\n",
    "                # than one. This is modifying things in place. See comment\n",
    "                # on previous call above.\n",
    "                buf_no = s.cur[level] - 1\n",
    "                _one_time_process(s.buf, s.G, s.past_intensity,\n",
    "                                  s.future_intensity, s.label_array, num_bufs,\n",
    "                                  s.num_pixels, s.img_per_level, level, buf_no,\n",
    "                                  s.norm, s.lev_len)\n",
    "                level += 1\n",
    "\n",
    "                # Checking whether there is next level for processing\n",
    "                processing = level < num_levels\n",
    "\n",
    "        # If any past intensities are zero, then g2 cannot be normalized at\n",
    "        # those levels. This if/else code block is basically preventing\n",
    "        # divide-by-zero errors.\n",
    "        if len(np.where(s.past_intensity == 0)[0]) != 0:\n",
    "            g_max = np.where(s.past_intensity == 0)[0][0]\n",
    "        else:\n",
    "            g_max = s.past_intensity.shape[0]\n",
    "\n",
    "        g2 = (s.G[:g_max] / (s.past_intensity[:g_max] *\n",
    "                             s.future_intensity[:g_max]))\n",
    "        yield results(g2, s.lag_steps[:g_max], s)\n",
    "\n",
    "\n",
    "def multi_tau_auto_corr(num_levels, num_bufs, labels, images):\n",
    "    \"\"\"Wraps generator implementation of multi-tau\n",
    "\n",
    "    Original code(in Yorick) for multi tau auto correlation\n",
    "    author: Mark Sutton\n",
    "\n",
    "    For parameter description, please reference the docstring for\n",
    "    lazy_one_time. Note that there is an API difference between this function\n",
    "    and `lazy_one_time`. The `images` arugment is at the end of this function\n",
    "    signature here for backwards compatibility, but is the first argument in\n",
    "    the `lazy_one_time()` function. The semantics of the variables remain\n",
    "    unchanged.\n",
    "    \"\"\"\n",
    "    gen = lazy_one_time(images, num_levels, num_bufs, labels)\n",
    "    for result in gen:\n",
    "        pass\n",
    "    return result.g2, result.lag_steps\n",
    "\n",
    "\n",
    "def _validate_and_transform_inputs(num_bufs, num_levels, labels):\n",
    "    \"\"\"\n",
    "    This is a helper function to validate inputs and create initial state\n",
    "    inputs for both one time and two time correlation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_bufs : int\n",
    "    num_levels : int\n",
    "    labels : array\n",
    "        labeled array of the same shape as the image stack;\n",
    "        each ROI is represented by a distinct label (i.e., integer)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    label_array : array\n",
    "        labels of the required region of interests(ROI's)\n",
    "    pixel_list : array\n",
    "        1D array of indices into the raveled image for all\n",
    "        foreground pixels (labeled nonzero)\n",
    "        e.g., [5, 6, 7, 8, 14, 15, 21, 22]\n",
    "    num_rois : int\n",
    "        number of region of interests (ROI)\n",
    "    num_pixels : array\n",
    "        number of pixels in each ROI\n",
    "    lag_steps : array\n",
    "        the times at which the correlation was computed\n",
    "    buf : array\n",
    "        image data for correlation\n",
    "    img_per_level : array\n",
    "        to track how many images processed in each level\n",
    "    track_level : array\n",
    "        to track processing each level\n",
    "    cur : array\n",
    "        to increment the buffer\n",
    "    norm : dict\n",
    "        to track bad images\n",
    "    lev_len : array\n",
    "        length of each levels\n",
    "    \"\"\"\n",
    "    if num_bufs % 2 != 0:\n",
    "        raise ValueError(\"There must be an even number of `num_bufs`. You \"\n",
    "                         \"provided %s\" % num_bufs)\n",
    "    label_array, pixel_list = roi.extract_label_indices(labels)\n",
    "\n",
    "    # map the indices onto a sequential list of integers starting at 1\n",
    "    label_mapping = {label: n+1\n",
    "                     for n, label in enumerate(np.unique(label_array))}\n",
    "    # remap the label array to go from 1 -> max(_labels)\n",
    "    for label, n in label_mapping.items():\n",
    "        label_array[label_array == label] = n\n",
    "\n",
    "    # number of ROI's\n",
    "    num_rois = len(label_mapping)\n",
    "\n",
    "    # stash the number of pixels in the mask\n",
    "    num_pixels = np.bincount(label_array)[1:]\n",
    "\n",
    "    # Convert from num_levels, num_bufs to lag frames.\n",
    "    tot_channels, lag_steps, dict_lag = utils.multi_tau_lags(num_levels, num_bufs)\n",
    "\n",
    "    # these norm and lev_len will help to find the one time correlation\n",
    "    # normalization norm will updated when there is a bad image\n",
    "    norm = {key: [0] * len(dict_lag[key]) for key in (dict_lag.keys())}\n",
    "    lev_len = np.array([len(dict_lag[i]) for i in (dict_lag.keys())])\n",
    "\n",
    "    # Ring buffer, a buffer with periodic boundary conditions.\n",
    "    # Images must be keep for up to maximum delay in buf.\n",
    "    buf = np.zeros((num_levels, num_bufs, len(pixel_list)),\n",
    "                   dtype=np.float64)\n",
    "    # to track how many images processed in each level\n",
    "    img_per_level = np.zeros(num_levels, dtype=np.int64)\n",
    "    # to track which levels have already been processed\n",
    "    track_level = np.zeros(num_levels, dtype=bool)\n",
    "    # to increment buffer\n",
    "    cur = np.ones(num_levels, dtype=np.int64)\n",
    "\n",
    "    return (label_array, pixel_list, num_rois, num_pixels,\n",
    "            lag_steps, buf, img_per_level, track_level, cur,\n",
    "            norm, lev_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _one_time_process(buf, G, past_intensity_norm, future_intensity_norm,\n",
    "                      label_array, num_bufs, num_pixels, img_per_level,\n",
    "                      level, buf_no, norm, lev_len):\n",
    "    \"\"\"Reference implementation of the inner loop of multi-tau one time\n",
    "    correlation\n",
    "\n",
    "    This helper function calculates G, past_intensity_norm and\n",
    "    future_intensity_norm at each level, symmetric normalization is used.\n",
    "\n",
    "    .. warning :: This modifies inputs in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    buf : array\n",
    "        image data array to use for correlation\n",
    "    G : array\n",
    "        matrix of auto-correlation function without normalizations\n",
    "    past_intensity_norm : array\n",
    "        matrix of past intensity normalizations\n",
    "    future_intensity_norm : array\n",
    "        matrix of future intensity normalizations\n",
    "    label_array : array\n",
    "        labeled array where all nonzero values are ROIs\n",
    "    num_bufs : int, even\n",
    "        number of buffers(channels)\n",
    "    num_pixels : array\n",
    "        number of pixels in certain ROI's\n",
    "        ROI's, dimensions are : [number of ROI's]X1\n",
    "    img_per_level : array\n",
    "        to track how many images processed in each level\n",
    "    level : int\n",
    "        the current multi-tau level\n",
    "    buf_no : int\n",
    "        the current buffer number\n",
    "    norm : dict\n",
    "        to track bad images\n",
    "    lev_len : array\n",
    "        length of each level\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    .. math::\n",
    "        G = <I(\\tau)I(\\tau + delay)>\n",
    "    .. math::\n",
    "        past_intensity_norm = <I(\\tau)>\n",
    "    .. math::\n",
    "        future_intensity_norm = <I(\\tau + delay)>\n",
    "    \"\"\"\n",
    "    img_per_level[level] += 1\n",
    "    print (img_per_level[level])\n",
    "    print (\"num_bufs\", num_bufs)\n",
    "    # in multi-tau correlation, the subsequent levels have half as many\n",
    "    # buffers as the first\n",
    "    i_min = num_bufs // 2 if level else 0\n",
    "    print (\"i_min\", i_min)\n",
    "    if img_per_level[level]<2:\n",
    "        value = img_per_level[level]\n",
    "    else:\n",
    "        \n",
    "    \n",
    "    p = Pool(process=4)\n",
    "    G1, past_intesnity_norm1, future_intensity_norm1 = multi_process(buf, G,\n",
    "                                                                     past_intensity_norm,\n",
    "                                                                     future_intensity_norm,\n",
    "                                                                  label_array, num_bufs,\n",
    "                                                                  num_pixels, img_per_level,\n",
    "                                                                  level, buf_no, norm,\n",
    "                                                                  lev_len, i_min, value)\n",
    "    #for i in range(i_min, min(img_per_level[level], num_bufs)):\n",
    "    #    # compute the index into the autocorrelation matrix\n",
    "    #    t_index = level * num_bufs / 2 + i\n",
    "    #    delay_no = (buf_no - i) % num_bufs\n",
    "\n",
    "    #    # get the images for correlating\n",
    "    #    past_img = buf[level, delay_no]\n",
    "    #    future_img = buf[level, buf_no]\n",
    "\n",
    "    #    # find the normalization that can work both for bad_images\n",
    "    #    #  and good_images\n",
    "    #    ind = int(t_index - lev_len[:level].sum())\n",
    "    #    normalize = img_per_level[level] - i - norm[level+1][ind]\n",
    "\n",
    "    #    # take out the past_ing and future_img created using bad images\n",
    "    #    # (bad images are converted to np.nan array)\n",
    "    #    if np.isnan(past_img).any() or np.isnan(future_img).any():\n",
    "    #        norm[level + 1][ind] += 1\n",
    "    #    else:\n",
    "    #        for w, arr in zip([past_img*future_img, past_img, future_img],\n",
    "    #                          [G, past_intensity_norm, future_intensity_norm]):\n",
    "    #            binned = np.bincount(label_array, weights=w)[1:]\n",
    "    #            arr[t_index] += ((binned / num_pixels -\n",
    "    #                              arr[t_index]) / normalize)\n",
    "                \n",
    "    # print (\"G\", G+G2)\n",
    "   \n",
    "    return None  # modifies arguments in place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_levels = 5\n",
    "num_bufs = 4  # must be even\n",
    "xdim = 100\n",
    "ydim = 100\n",
    "stack_size = 10\n",
    "synthetic_data = np.random.randint(1, 10, (stack_size, xdim, ydim))\n",
    "\n",
    "rois = np.zeros_like(synthetic_data[0])\n",
    "# make sure that the ROIs can be any integers greater than 1. They do not\n",
    "# have to start at 1 and be continuous\n",
    "rois[0:xdim//10, 0:ydim//10] = 5\n",
    "rois[xdim//10:xdim//5, ydim//10:ydim//5] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G2 = np.array([[ 62.82,  57.9 ], [  0. ,    0.  ], [  0. ,    0.  ], [  0.  ,   0.  ],\n",
    "     [  0. ,    0.  ], \n",
    "     [  0. ,    0.  ],\n",
    "     [  0. ,   0.  ],\n",
    "     [  0. ,    0.  ],\n",
    "     [ 20. ,   0.  ],\n",
    "     [  0. ,    30.  ],\n",
    "     [  0. ,   0.  ],\n",
    "     [  0. ,    0.  ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_process(buf, G, past_intensity_norm, future_intensity_norm,\n",
    "                  label_array, num_bufs, num_pixels, img_per_level,\n",
    "                  level, buf_no, norm, lev_len, i_min, value):\n",
    "    for i in range(i_min, min(value, num_bufs)):\n",
    "        # compute the index into the autocorrelation matrix\n",
    "        t_index = level * num_bufs / 2 + i\n",
    "        delay_no = (buf_no - i) % num_bufs\n",
    "\n",
    "        # get the images for correlating\n",
    "        past_img = buf[level, delay_no]\n",
    "        future_img = buf[level, buf_no]\n",
    "\n",
    "        # find the normalization that can work both for bad_images\n",
    "        #  and good_images\n",
    "        ind = int(t_index - lev_len[:level].sum())\n",
    "        normalize = img_per_level[level] - i - norm[level+1][ind]\n",
    "\n",
    "        # take out the past_ing and future_img created using bad images\n",
    "        # (bad images are converted to np.nan array)\n",
    "        if np.isnan(past_img).any() or np.isnan(future_img).any():\n",
    "            norm[level + 1][ind] += 1\n",
    "        else:\n",
    "            for w, arr in zip([past_img*future_img, past_img, future_img],\n",
    "                              [G, past_intensity_norm, future_intensity_norm]):\n",
    "                binned = np.bincount(label_array, weights=w)[1:]\n",
    "                arr[t_index] += ((binned / num_pixels -\n",
    "                                  arr[t_index]) / normalize)\n",
    "    return G, past_intensity_norm, future_intensity_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "2\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "1\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "3\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "4\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "2\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "1\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "5\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "6\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "3\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "7\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "8\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "4\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "2\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "1\n",
      "num_bufs 4\n",
      "i_min 2\n",
      "9\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "10\n",
      "num_bufs 4\n",
      "i_min 0\n",
      "5\n",
      "num_bufs 4\n",
      "i_min 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sameera/mc/envs/py3k/lib/python3.4/site-packages/ipykernel/__main__.py:57: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/sameera/mc/envs/py3k/lib/python3.4/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/sameera/mc/envs/py3k/lib/python3.4/site-packages/ipykernel/__main__.py:29: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "g2, lag = multi_tau_auto_corr(num_levels, num_bufs, rois, synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26762543,  1.24731427],\n",
       "       [ 1.01973219,  0.99807769],\n",
       "       [ 1.02009913,  1.00215313],\n",
       "       [ 0.98522036,  1.01009746],\n",
       "       [ 0.99950494,  0.9974503 ],\n",
       "       [ 0.98777353,  0.99304597]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26590631,  1.26872311],\n",
       "       [ 1.01546557,  1.00025986],\n",
       "       [ 1.0056585 ,  0.99004235],\n",
       "       [ 1.01136044,  1.00628501],\n",
       "       [ 1.00733236,  0.99759216],\n",
       "       [ 1.00967967,  0.9998498 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
